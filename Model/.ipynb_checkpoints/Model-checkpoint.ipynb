{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import Sequence\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the section dedicated to contatain the results of the sampling\n",
    "# Purpose here is to try and use the UNET architecture and understand the\n",
    "# first steps of building and training the neural network\n",
    "sampled_pickles = '/home/omar/Desktop/sampled_output/'\n",
    "smooth = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step is to choose random 26 patients as training pool. The\n",
    "# remaining 3 are our test pool.\n",
    "\n",
    "patients = os.listdir(sampled_pickles)\n",
    "random.shuffle(patients)\n",
    "# training_patients = patients[:26]\n",
    "training_patients = ['TCGA-76-6282.pickle', 'TCGA-76-4932.pickle', 'TCGA-02-0046.pickle', 'TCGA-06-0138.pickle', 'TCGA-76-6657.pickle', 'TCGA-76-4935.pickle', 'TCGA-19-5960.pickle', 'TCGA-76-6280.pickle', 'TCGA-02-0006.pickle', 'TCGA-19-1789.pickle', 'TCGA-02-0009.pickle', 'TCGA-19-0963.pickle', 'TCGA-02-0086.pickle', 'TCGA-06-0149.pickle', 'TCGA-06-0179.pickle', 'TCGA-06-2570.pickle', 'TCGA-02-0075.pickle', 'TCGA-12-0616.pickle', 'TCGA-02-0085.pickle', 'TCGA-06-5417.pickle', 'TCGA-06-0145.pickle', 'TCGA-08-0355.pickle', 'TCGA-02-0054.pickle', 'TCGA-19-2624.pickle', 'TCGA-06-0177.pickle', 'TCGA-02-0106.pickle']\n",
    "# test_patients = patients[26:29]\n",
    "test_patients = ['TCGA-08-0509.pickle', 'TCGA-08-0520.pickle', 'TCGA-06-6389.pickle']\n",
    "image_width = 256\n",
    "image_height = 256\n",
    "# batch_size= 16\n",
    "current_dir = '/home/omar/Desktop/Generalization/Model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(path, list_of_patients):\n",
    "    # Setting the lists that will contain the images and masks\n",
    "    img_height = 256\n",
    "    img_width = 256\n",
    "    total_scans = 0\n",
    "    seg = 0\n",
    "    for patient in list_of_patients:\n",
    "        patient_path = path + patient\n",
    "        pickle_file = open(\"%s\"%(patient_path), \"rb\")\n",
    "        patient_data = pickle.load(pickle_file)\n",
    "        total_scans += len(patient_data[0]) + len(patient_data[1]) + len(patient_data[2]) + len(patient_data[3])\n",
    "    \n",
    "    imgs = np.ndarray((total_scans, img_width, img_height), dtype = np.uint8)\n",
    "    masks = np.ndarray((total_scans, img_width, img_height), dtype = np.uint8)\n",
    "    \n",
    "    indexer = 0\n",
    "    for patient in list_of_patients:\n",
    "        print('Current Patient: %s' % (patient))\n",
    "        patient_path = path + patient\n",
    "        pickle_file = open(\"%s\"%(patient_path), \"rb\")\n",
    "        patient_data = pickle.load(pickle_file)\n",
    "        for scan in range(len(patient_data)):\n",
    "            if scan != 4:\n",
    "                for array in range(len(patient_data[scan])):\n",
    "                    img = patient_data[scan][array]\n",
    "                    img_mask = patient_data[4][scan][array]\n",
    "                    imgs[indexer] = img\n",
    "                    masks[indexer] = img_mask\n",
    "                    indexer+=1\n",
    "    os.chdir(current_dir)\n",
    "    np.save('imgs_train.npy', imgs)\n",
    "    np.save('img_masks_train.npy', masks)\n",
    "    print('Images for training and masking saved to .npy files.')\n",
    "\n",
    "    \n",
    "def load_data():\n",
    "    imgs = np.load('imgs_train.npy')\n",
    "    masks = np.load('img_masks_train.npy')\n",
    "    return imgs, masks\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(imgs):\n",
    "    processed_images =np.ndarray((imgs.shape[0], image_width, image_height), dtype=np.uint8)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        processed_images[i] = resize(imgs[i], (image_width, image_height), preserve_range=True)\n",
    "    \n",
    "    processed_images = processed_images[..., np.newaxis]\n",
    "    return processed_images\n",
    "\n",
    "\n",
    "\n",
    "def prepare_test(path, list_of_patients):\n",
    "    img_height = 256\n",
    "    img_width = 256\n",
    "    total_scans = 0\n",
    "    seg = 0\n",
    "    for patient in list_of_patients:\n",
    "        patient_path = path + patient\n",
    "        pickle_file = open(\"%s\"%(patient_path), \"rb\")\n",
    "        patient_data = pickle.load(pickle_file)\n",
    "        total_scans += len(patient_data[0]) + len(patient_data[1]) + len(patient_data[2]) + len(patient_data[3])\n",
    "    \n",
    "    imgs = np.ndarray((total_scans, image_width, image_height), dtype = np.uint8)\n",
    "    ids = np.ndarray((total_scans, ), dtype=np.int32)\n",
    "    \n",
    "    indexer = 0\n",
    "    for patient in list_of_patients:\n",
    "        print('Current Patient: %s' % (patient))\n",
    "        patient_path = path + patient\n",
    "        pickle_file = open(\"%s\"%(patient_path), \"rb\")\n",
    "        patient_data = pickle.load(pickle_file)\n",
    "        for scan in range(len(patient_data)):\n",
    "            if scan != 4:\n",
    "                for array in range(len(patient_data[scan])):\n",
    "                    img = patient_data[scan][array]\n",
    "                    imgID = patient_data[4][scan][array]\n",
    "                    imgs[indexer] = img\n",
    "                    ids[indexer] = imgID\n",
    "                    indexer+=1\n",
    "    os.chdir(current_dir)\n",
    "    np.save('imgs_test.npy', imgs)\n",
    "    np.save('img_id_test.npy', ids)\n",
    "    print('Images for testing and ids saved to .npy files.')\n",
    "    \n",
    "\n",
    "def load_test():\n",
    "    imgs_test = np.load('imgs_test.npy')\n",
    "    imgs_id = np.load('img_id_test.npy')\n",
    "    return imgs_test, imgs_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated preprocessing attempt\n",
    "def preprocess_training(images):\n",
    "    output = images.reshape(images.shape[0], 256, 256, 1)\n",
    "    output = output.astype('float32')\n",
    "    output/=255\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "def UNet():\n",
    "    inputs = Input((image_width, image_height, 1))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "#     Second Implementation\n",
    "#     model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset\n",
      "['TCGA-76-6282.pickle', 'TCGA-76-4932.pickle', 'TCGA-02-0046.pickle', 'TCGA-06-0138.pickle', 'TCGA-76-6657.pickle', 'TCGA-76-4935.pickle', 'TCGA-19-5960.pickle', 'TCGA-76-6280.pickle', 'TCGA-02-0006.pickle', 'TCGA-19-1789.pickle', 'TCGA-02-0009.pickle', 'TCGA-19-0963.pickle', 'TCGA-02-0086.pickle', 'TCGA-06-0149.pickle', 'TCGA-06-0179.pickle', 'TCGA-06-2570.pickle', 'TCGA-02-0075.pickle', 'TCGA-12-0616.pickle', 'TCGA-02-0085.pickle', 'TCGA-06-5417.pickle', 'TCGA-06-0145.pickle', 'TCGA-08-0355.pickle', 'TCGA-02-0054.pickle', 'TCGA-19-2624.pickle', 'TCGA-06-0177.pickle', 'TCGA-02-0106.pickle']\n",
      "Test Dataset\n",
      "['TCGA-08-0509.pickle', 'TCGA-08-0520.pickle', 'TCGA-06-6389.pickle']\n"
     ]
    }
   ],
   "source": [
    "print('Training Dataset')\n",
    "print(training_patients)\n",
    "print(\"Test Dataset\")\n",
    "print(test_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Generating Data and masks\n",
      "------------------------------\n",
      "Current Patient: TCGA-76-6282.pickle\n",
      "Current Patient: TCGA-76-4932.pickle\n",
      "Current Patient: TCGA-02-0046.pickle\n",
      "Current Patient: TCGA-06-0138.pickle\n",
      "Current Patient: TCGA-76-6657.pickle\n",
      "Current Patient: TCGA-76-4935.pickle\n",
      "Current Patient: TCGA-19-5960.pickle\n",
      "Current Patient: TCGA-76-6280.pickle\n",
      "Current Patient: TCGA-02-0006.pickle\n",
      "Current Patient: TCGA-19-1789.pickle\n",
      "Current Patient: TCGA-02-0009.pickle\n",
      "Current Patient: TCGA-19-0963.pickle\n",
      "Current Patient: TCGA-02-0086.pickle\n",
      "Current Patient: TCGA-06-0149.pickle\n",
      "Current Patient: TCGA-06-0179.pickle\n",
      "Current Patient: TCGA-06-2570.pickle\n",
      "Current Patient: TCGA-02-0075.pickle\n",
      "Current Patient: TCGA-12-0616.pickle\n",
      "Current Patient: TCGA-02-0085.pickle\n",
      "Current Patient: TCGA-06-5417.pickle\n",
      "Current Patient: TCGA-06-0145.pickle\n",
      "Current Patient: TCGA-08-0355.pickle\n",
      "Current Patient: TCGA-02-0054.pickle\n",
      "Current Patient: TCGA-19-2624.pickle\n",
      "Current Patient: TCGA-06-0177.pickle\n",
      "Current Patient: TCGA-02-0106.pickle\n",
      "Images for training and masking saved to .npy files.\n",
      "------------------------------\n",
      "Images and mask data created.\n"
     ]
    }
   ],
   "source": [
    "# Creating and saving data selected by randomizer.\n",
    "print('-'*30)\n",
    "print('Generating Data and masks')\n",
    "print('-'*30)\n",
    "prepare_data(sampled_pickles, training_patients)\n",
    "print('-'*30)\n",
    "print('Images and mask data created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Loading training and testing data.\n",
      "------------------------------\n",
      "Data Loaded Successfully.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Loading data from npy files created.\n",
    "print('-'*30)\n",
    "print(\"Loading training dataset.\")\n",
    "print('-'*30)\n",
    "imgs, masks = load_data()\n",
    "# test_img, test_mask = load_test()\n",
    "print('Data Loaded Successfully.')\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Training with loaded data initiation.\n",
      "------------------------------\n",
      "Preprocessing images and masks\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 842 into shape (842,256,256,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-34dbe0ae896d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmask_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtest_img_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtest_mask_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-b4ef7a38cb07>\u001b[0m in \u001b[0;36mpreprocess_training\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Updated preprocessing attempt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m/=\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 842 into shape (842,256,256,1)"
     ]
    }
   ],
   "source": [
    "print('-'*30)\n",
    "print('Training with loaded data initiation.')\n",
    "print('-'*30)\n",
    "print('Preprocessing images and masks')\n",
    "\n",
    "# Normalizing the data\n",
    "img_final = preprocess_training(imgs)\n",
    "mask_final = preprocess_training(masks)\n",
    "# test_img_final = preprocess_training(test_img)\n",
    "# test_mask_final = preprocess_training(test_mask)\n",
    "\n",
    "\n",
    "# train_gen = ImageDataGenerator(rotation_range=8, \n",
    "#                                width_shift_range=0.08, \n",
    "#                                shear_range=0.3, \n",
    "#                                height_shift_range=0.08, \n",
    "#                                zoom_range=0.08 )\n",
    "# test_gen = ImageDataGenerator()\n",
    "\n",
    "# training_dataset = train_gen.flow(img_final, mask_final, batch_size=64)\n",
    "# testing_dataset = train_gen.flow(test_img_final, test_mask_final, batch_size=64)\n",
    "\n",
    "imgs_train = img_final.astype('float32')\n",
    "mean = np.mean(imgs_train)\n",
    "std = np.std(imgs_train)\n",
    "\n",
    "imgs_train -= mean\n",
    "imgs_train /= std\n",
    "\n",
    "masks_train = mask_final.astype('float32')\n",
    "masks_train /= 255\n",
    "\n",
    "print('-'*30)\n",
    "print('Compiling model.')\n",
    "print(img_final[0][10])\n",
    "\n",
    "\n",
    "\n",
    "model = UNet()\n",
    "model.summary()\n",
    "model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for scan in range(5):\n",
    "#     for array in range(5):\n",
    "        \n",
    "#         fig  = plt.figure(figsize=(5,5))\n",
    "#         a = fig.add_subplot(1, 2, 1)\n",
    "#         imgplot = plt.imshow(img_final[scan][array])\n",
    "\n",
    "#         a = fig.add_subplot(1, 2, 2)\n",
    "#         imgplot = plt.imshow(mask_final[scan][array])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for slice in range(20):\n",
    "#     plt.figure(figsize=(5,5))\n",
    "#     plt.imshow(np.squeeze(masks_train[slice]), 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('-'*30)\n",
    "# print('Fitting Data.')\n",
    "# print('-'*30)\n",
    "\n",
    "# model.fit(imgs_train, masks_train, batch_size=32, nb_epoch=20, verbose=1, shuffle=True,\n",
    "#               validation_split=0.2,\n",
    "#               callbacks=[model_checkpoint])\n",
    "print('Fitting Complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the test patients\n",
    "\n",
    "print('-'*30)\n",
    "print('Creating Test Data.')\n",
    "print('-'*30)\n",
    "prepare_test(sampled_pickles, test_patients)\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and preprocessing the test patient data.\n",
    "print('-'*30)\n",
    "print('Loading and preprocessing test data...')\n",
    "print('-'*30)\n",
    "imgs_test, imgs_id_test = load_test()\n",
    "\n",
    "imgs_test = preprocess(imgs_test)\n",
    "\n",
    "imgs_test = imgs_test.astype('float32')\n",
    "imgs_test -= mean\n",
    "imgs_test /= std\n",
    "\n",
    "print('-'*30)\n",
    "print('Loading saved weights...')\n",
    "print('-'*30)\n",
    "model.load_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*30)\n",
    "print('Predicting masks on test data...')\n",
    "print('-'*30)\n",
    "imgs_mask_test = model.predict(imgs_test, verbose=1)\n",
    "out_dir = '/home/omar/Desktop/Generalization/Model/OUT/'\n",
    "os.chdir(out_dir)\n",
    "np.save('imgs_mask_test.npy', imgs_mask_test)\n",
    "print('-' * 30)\n",
    "print('Saving predicted masks to files...')\n",
    "print('-' * 30)\n",
    "pred_dir = 'preds'\n",
    "if not os.path.exists(pred_dir):\n",
    "    os.mkdir(pred_dir)\n",
    "for image, image_id in zip(imgs_mask_test, imgs_id_test):\n",
    "    ind = 1\n",
    "    image = (image[:, :, 0] * 255.).astype(np.uint8)\n",
    "    imsave(os.path.join(pred_dir, str(ind) + '_pred.png'), image)\n",
    "    ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
