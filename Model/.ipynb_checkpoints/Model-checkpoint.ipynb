{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import Sequence\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the section dedicated to contatain the results of the sampling\n",
    "# Purpose here is to try and use the UNET architecture and understand the\n",
    "# first steps of building and training the neural network\n",
    "sampled_pickles = '/home/omar/Desktop/sampled_output/'\n",
    "smooth = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step is to choose random 26 patients as training pool. The\n",
    "# remaining 3 are our test pool.\n",
    "\n",
    "patients = os.listdir(sampled_pickles)\n",
    "random.shuffle(patients)\n",
    "training_patients = patients[:26]\n",
    "test_patients = patients[26:29]\n",
    "image_width = 256\n",
    "image_height = 256\n",
    "# batch_size= 16\n",
    "current_dir = '/home/omar/Desktop/Generalization/Model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prepare_data(path, list_of_patients):\n",
    "    # Setting the lists that will contain the images and masks\n",
    "    img_height = 256\n",
    "    img_width = 256\n",
    "    total_scans = 0\n",
    "    seg = 0\n",
    "    for patient in list_of_patients:\n",
    "        patient_path = path + patient\n",
    "        pickle_file = open(\"%s\"%(patient_path), \"rb\")\n",
    "        patient_data = pickle.load(pickle_file)\n",
    "        total_scans += len(patient_data[0]) + len(patient_data[1]) + len(patient_data[2]) + len(patient_data[3])\n",
    "    \n",
    "    imgs = np.ndarray((total_scans, img_width, img_height), dtype = np.uint8)\n",
    "    masks = np.ndarray((total_scans, img_width, img_height), dtype = np.uint8)\n",
    "    \n",
    "    indexer = 0\n",
    "    for patient in list_of_patients:\n",
    "        print('Current Patient: %s' % (patient))\n",
    "        patient_path = path + patient\n",
    "        pickle_file = open(\"%s\"%(patient_path), \"rb\")\n",
    "        patient_data = pickle.load(pickle_file)\n",
    "        for scan in range(len(patient_data)):\n",
    "            if scan != 4:\n",
    "                for array in range(len(patient_data[scan])):\n",
    "                    img = patient_data[scan][array]\n",
    "                    img_mask = patient_data[4][scan][array]\n",
    "                    imgs[indexer] = img\n",
    "                    masks[indexer] = img_mask\n",
    "                    indexer+=1\n",
    "    os.chdir(current_dir)\n",
    "    np.save('imgs_train.npy', imgs)\n",
    "    np.save('img_masks_train.npy', masks)\n",
    "    print('Images for training and masking saved to .npy files.')\n",
    "\n",
    "    \n",
    "def load_data():\n",
    "    imgs = np.load('imgs_train.npy')\n",
    "    masks = np.load('img_masks_train.npy')\n",
    "    return imgs, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def UNet():\n",
    "    inputs = Input((image_width, image_height, 1))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Generating Data and masks\n",
      "------------------------------\n",
      "Current Patient: TCGA-02-0009.pickle\n",
      "Current Patient: TCGA-06-0138.pickle\n",
      "Current Patient: TCGA-06-6389.pickle\n",
      "Current Patient: TCGA-76-6657.pickle\n",
      "Current Patient: TCGA-76-4935.pickle\n",
      "Current Patient: TCGA-02-0086.pickle\n",
      "Current Patient: TCGA-02-0054.pickle\n",
      "Current Patient: TCGA-02-0106.pickle\n",
      "Current Patient: TCGA-06-0149.pickle\n",
      "Current Patient: TCGA-08-0355.pickle\n",
      "Current Patient: TCGA-76-6280.pickle\n",
      "Current Patient: TCGA-19-1789.pickle\n",
      "Current Patient: TCGA-06-2570.pickle\n",
      "Current Patient: TCGA-06-5417.pickle\n",
      "Current Patient: TCGA-02-0046.pickle\n",
      "Current Patient: TCGA-19-0963.pickle\n",
      "Current Patient: TCGA-76-6282.pickle\n",
      "Current Patient: TCGA-02-0085.pickle\n",
      "Current Patient: TCGA-06-0177.pickle\n",
      "Current Patient: TCGA-08-0520.pickle\n",
      "Current Patient: TCGA-02-0006.pickle\n",
      "Current Patient: TCGA-12-0616.pickle\n",
      "Current Patient: TCGA-76-4932.pickle\n",
      "Current Patient: TCGA-08-0509.pickle\n",
      "Current Patient: TCGA-19-2624.pickle\n",
      "Current Patient: TCGA-06-0145.pickle\n",
      "Images for training and masking saved to .npy files.\n",
      "------------------------------\n",
      "Images and mask data created.\n"
     ]
    }
   ],
   "source": [
    "# Creating and saving data selected by randomizer.\n",
    "print('-'*30)\n",
    "print('Generating Data and masks')\n",
    "print('-'*30)\n",
    "prepare_data(sampled_pickles, training_patients)\n",
    "print('-'*30)\n",
    "print('Images and mask data created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Loading created data.\n",
      "------------------------------\n",
      "Data Loaded Successfully.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Loading data from npy files created.\n",
    "print('-'*30)\n",
    "print(\"Loading created data.\")\n",
    "print('-'*30)\n",
    "imgs, masks = load_data()\n",
    "print('Data Loaded Successfully.')\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*30)\n",
    "print('Generating Data and masks')\n",
    "print('-'*30)\n",
    "# imgs, masks = prepare_data(sampled_pickles, training_patients)\n",
    "prepare_data(sampled_pickles, training_patients)\n",
    "# imgs_train = np.array(imgs, np.float32)/255.\n",
    "# masks_train = np.array(masks, np.float32)/255.\n",
    "# imgs_train = np.concatenate(imgs, axis=0)\n",
    "# masks_train = np.concatenate(masks, axis=0)\n",
    "# imgs_train = np.asarray(imgs, dtype=np.float32)\n",
    "# masks_train = np.asarray(masks, dtype=np.float32)\n",
    "# print('-'*30)\n",
    "# print('Compiling and creating model')\n",
    "# print('-'*30)\n",
    "# model = UNet()\n",
    "# model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "# print('-'*30)\n",
    "# print('Fitting model...')\n",
    "# print('-'*30)\n",
    "# model.fit(imgs_train, masks_train, batch_size=32, nb_epoch=20, verbose=1,\n",
    "#           shuffle=True, validation_split=0.2, callbacks=[model_checkpoint])\n",
    "# print('-'*30)\n",
    "# print('Fitting Complete')\n",
    "# print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
